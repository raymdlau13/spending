{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd197329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def assign_category(description): #EXXO NMOBIL\n",
    "    if re.search( r\"(^EXXO\\s*N|^SPEEDWAY|^MAIN\\s+ST\\s+GAS|^SUNOCO|GULF\\s+OIL|CITGO|MAIN ST(REET)? GAS).*?\", str(description), re.IGNORECASE):\n",
    "        return \"Gas\"\n",
    "    elif re.search( r\"^Costco\\s+Annual\\s+Membership\\s+Renewal\", str(description), re.IGNORECASE):\n",
    "        return \"Fees and Adjustments\"\n",
    "    elif re.search( r\"(^COST\\s*CO\\s+WHSE.*?|WWW COSTCO COM|COSTCO)\", str(description), re.IGNORECASE):\n",
    "        return \"Costco\"\n",
    "    elif re.search( r\"^AMZN\\s+.*?\\s+GIFT\\s+CARD.*?\", str(description), re.IGNORECASE):\n",
    "        return \"Gift Card\"\n",
    "    elif re.search(r\"(MCDONALD(')*S|TANDOORI|DOMINO|5GUYS|PANDA PAVILLION|AMERICAN\\s*STEAKHOUSE|GYU-KAKU|TERIYAKI ONE|KARAVALLI|JAMROCK JERK|AUNTIE ANNES|BURGER KING|CAFE 1585|CENTRAL SEAFOOD HARTSDALE NY)\", str(description),re.IGNORECASE):\n",
    "        return \"Food & Drink\"\n",
    "    elif re.search(r\"(KITCHEN PARADISE|STARBUCKS|POPEYES|SGD DUBU|KUMO ULTIMATE SUSHI|Dinosaur Bar-B-Que|THAI SPICE|PANERA|DUNKIN|BIBBLE \\& SIP|SHAKE SHACK|BBQ CHICKEN|\\#1 ISTANBUL KEBAB HOUSE|TONY AND BENNYS|RED LOBSTER)\", str(description),re.IGNORECASE):\n",
    "        return \"Food & Drink\"\n",
    "    elif re.search(r\"(ENCHANTED SZECHUAN NORWALK CT|FIVE GUYS|FOOD COURT JAMAICA NY|GYRO GYRO HARTSDALE NY|GYROWORLD FLUSHING NY|HSD FOOD COURT|KFC|Kumo Sush|Lao Si Chua|MID HUDSON BUFFET KINGSTON NY|MINAR|MISTI CAFE|PEPPER LUNCH|POLLO A LA BRASA MIST)\", str(description),re.IGNORECASE):\n",
    "        return \"Food & Drink\"   \n",
    "    elif re.search(r\"(TACO BELL|TANDORI TASTE OF INDIA|THAI BASIL|THE BUFFET COLLEGE POINT NY|GO! GO! CURRY|WETZEL'S|Yellowtail Hibachi|YUM YUM TOO|ZIBETTO ESPRESSO|BUFFALO WILD WINGS|FANTASY CUISINE)\", str(description),re.IGNORECASE):\n",
    "        return \"Food & Drink\"\n",
    "    elif re.search(r\"(PATISSERIE DIDIER DUMAS NYACK NY|KPOT KOREAN BBQ|THAIBASIL|JOUMMAR RESTAURANT LLC)\", str(description),re.IGNORECASE):\n",
    "        return \"Food & Drink\"\n",
    "    elif re.search(r\"(TRADER JOE|H MART|FUJI MART|SHOPRITE|WAL-MART|ALDI|ASIA BAZAAR|CHANG JIANG SUPERMARKE FLUSHING NY|GOLD CITY SUPERMARKET FLUSHING NY|GOOD FORTUNE SUPERMARK|HUA LIAN SUPERMARKET|LA PLACITA|C \\& A SUPERMARKET|STEW LEONARDS|GMART MILFORD CT)\", str(description),re.IGNORECASE):\n",
    "        return \"Groceries\"\n",
    "    elif re.search(r\"(KUMO GROCERY STAMFORD CT|APPLE FARM)\", str(description),re.IGNORECASE):\n",
    "        return \"Groceries\"\n",
    "    elif re.search(r\"(TMOBILE|CT NATURAL GAS|CONNECTICUT NATURAL)\", str(description),re.IGNORECASE):\n",
    "        return \"Bills & Utilities\"\n",
    "    elif re.search(r\"(CHATGPT|OPENAI)\", str(description),re.IGNORECASE):\n",
    "        return \"Subscriptions\"\n",
    "    elif re.search(r\"(CVS\\/PHARMACY)\", str(description),re.IGNORECASE):\n",
    "        return \"Pharmacy\"\n",
    "    elif re.search(r\"(MARCUS MAYUS|GandelmanCardiology|RYE ORAL SURGERY|WESTCHESTER AVE DENTAL|GARRICK F WONG|RYE PERIODONTICS|PARKES MEDICAL CE|HSC MYCHART|TC CARDIOLOGY PC FLUSHING NY)\", str(description),re.IGNORECASE):\n",
    "        return \"Health & Wellness\"\n",
    "    elif re.search(r\"(EVA AIR|CATHAYPACAIR|UBER|MTA|TRIP[ .]COM|E-Z|EZPASS|Chase Travel)\", str(description),re.IGNORECASE):\n",
    "        return \"Travel\"\n",
    "    elif re.search(r\"(GEICO|HOMEOWNER)\", str(description),re.IGNORECASE):\n",
    "        return \"Insurance\"\n",
    "    else:\n",
    "        return \"Shopping\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be97218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        reader = PdfReader(pdf_file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "def extract_activities_from_text(text, year, month):\n",
    "    pattern = r\"^(\\d{2}\\/\\d{2})\\s+(.*?)\\s+((-?\\d{1,3}(,\\d{3})*)*\\.\\d{2})\"\n",
    "\n",
    "    lines = []\n",
    "    for line in text.split(\"\\n\"):\n",
    "        match = re.match(pattern,line) \n",
    "        if match:\n",
    "            if match.group(1)[:2] == \"12\" and month == \"01\":\n",
    "                this_year = str(int(year) - 1)\n",
    "            else:\n",
    "                this_year = year\n",
    "            # lines.append(f\"{match.group(1)}/{this_year},{match.group(2)},{match.group(3).replace(',','')}\")\n",
    "            lines.append((f\"{match.group(1)}/{this_year}\", match.group(2).strip(), match.group(3).replace(',','')))  # Update the tuple at index i\n",
    "\n",
    "    return lines\n",
    "\n",
    "\n",
    "directory_path = \"/Users/kingwanlau/Downloads/spending/chase\"\n",
    "pdf_files = glob.glob(os.path.join(directory_path, \"*.pdf\"))\n",
    "activities = []\n",
    "for pdf in pdf_files:\n",
    "    year = os.path.basename(pdf).split(\"-\")[0][:4]\n",
    "    month = os.path.basename(pdf).split(\"-\")[0][4:6]\n",
    "    text_data = extract_text_from_pdf(pdf)\n",
    "    activities += extract_activities_from_text(text_data, year, month)\n",
    "\n",
    "chase_old_activities_df = pd.DataFrame(activities, columns=['Transaction Date','Description','Amount'])\n",
    "\n",
    "chase_old_activities_df[\"Transaction Date\"] = pd.to_datetime(chase_old_activities_df[\"Transaction Date\"], format=\"%m/%d/%Y\")\n",
    "chase_old_activities_df[\"Amount\"] = chase_old_activities_df[\"Amount\"].astype(float)\n",
    "\n",
    "# delete rows for Auto Payment\n",
    "chase_old_activities_df = chase_old_activities_df[~chase_old_activities_df[\"Description\"].str.contains(r\"^AUTOMATIC\\s+PAYMENT\", na=False, regex=True)]\n",
    "chase_old_activities_df = chase_old_activities_df[~chase_old_activities_df[\"Description\"].str.contains(r\"^Payment\\s+Thank\\s+You\", na=False, regex=True)]\n",
    "\n",
    "\n",
    "chase_old_activities_df.insert(2, \"Category\", \"Shopping\")\n",
    "chase_old_activities_df[\"Category\"] = chase_old_activities_df[\"Description\"].apply(assign_category)\n",
    "\n",
    "chase_old_activities_df = chase_old_activities_df.sort_values(by=\"Transaction Date\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cf2a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "accounts_df = []\n",
    "spending_df = pd.DataFrame()\n",
    "directory_path = \"/Users/kingwanlau/Downloads/spending/chase\"\n",
    "csv_files = glob.glob(os.path.join(directory_path, \"Chase*.CSV\"))\n",
    "for i, csv_file in enumerate(csv_files):\n",
    "    if i == 0:\n",
    "        spending_df = pd.read_csv(csv_file)\n",
    "    else:\n",
    "        spending_df = pd.concat([spending_df,pd.read_csv(csv_file)], ignore_index=True)\n",
    "\n",
    "\n",
    "# Remove rows for Auto Payment\n",
    "spending_df = spending_df[spending_df[\"Type\"] != \"Payment\"]\n",
    "\n",
    "# drop columns\n",
    "spending_df = spending_df.drop(columns=[\"Post Date\", \"Memo\", \"Type\", \"Card\"])\n",
    "\n",
    "# convert to datetime type\n",
    "spending_df[\"Transaction Date\"] = pd.to_datetime(spending_df[\"Transaction Date\"], format=\"%m/%d/%Y\")\n",
    "\n",
    "# Convert Amount into Positive for better charting\n",
    "spending_df[\"Amount\"] = spending_df[\"Amount\"]*-1.0\n",
    "spending_df[\"Category\"] = spending_df[\"Description\"].apply(assign_category)\n",
    "\n",
    "spending_df = spending_df.sort_values(by=\"Transaction Date\", ascending=False)\n",
    "\n",
    "spending_df = pd.concat(\n",
    "    [ spending_df[spending_df[\"Transaction Date\"]>chase_old_activities_df[\"Transaction Date\"].max()]\n",
    "    ,  chase_old_activities_df  \n",
    "    ], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f2c040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "citibank_spending_df = pd.DataFrame()\n",
    "directory_path = \"/Users/kingwanlau/Downloads/spending/citi\"\n",
    "citibank_spending_csvs = glob.glob(os.path.join(directory_path, \"Citi*.CSV\"))\n",
    "\n",
    "for citibank_spending_csv in citibank_spending_csvs:\n",
    "    if citibank_spending_df.empty:\n",
    "        citibank_spending_df = pd.read_csv(citibank_spending_csv)\n",
    "    else:\n",
    "        citibank_spending_df = pd.concat([citibank_spending_df,pd.read_csv(citibank_spending_csv)], ignore_index=True)\n",
    "\n",
    "# assign Credit to Debit if it is not in NaN\n",
    "citibank_spending_df.loc[citibank_spending_df[\"Credit\"].notna(),\"Debit\"] =citibank_spending_df[\"Credit\"] #*-1.0\n",
    "\n",
    "# drop columns\n",
    "citibank_spending_df = citibank_spending_df.drop(columns=[\"Status\", \"Member Name\", \"Credit\"])\n",
    "\n",
    "# delete rows for Auto Payment\n",
    "citibank_spending_df = citibank_spending_df[~citibank_spending_df[\"Description\"].str.contains(r\"^AUTOPAY\\s+.*?\\s+AUTO-PMT$\", na=False, regex=True)]\n",
    "\n",
    "# rename column\n",
    "citibank_spending_df = citibank_spending_df.rename(columns={\"Date\": \"Transaction Date\", \"Debit\": \"Amount\"})\n",
    "\n",
    "# convert to datetime type\n",
    "citibank_spending_df[\"Transaction Date\"] = pd.to_datetime(citibank_spending_df[\"Transaction Date\"], format=\"%m/%d/%Y\")\n",
    "\n",
    "directory_path = \"/Users/kingwanlau/Downloads/spending/citi\"\n",
    "pdf_files = glob.glob(os.path.join(directory_path, \"*.pdf\"))\n",
    "activities = []\n",
    "# activities = [('Transaction Date','Description','Amount')]\n",
    "for pdf_file in pdf_files:\n",
    "    month, year = os.path.basename(pdf_file).split(\".\")[0].split(\" \")\n",
    "    this_activites = []\n",
    "    with pdfplumber.open(pdf_file) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "            # this_activites += re.findall(r\"(\\d{2}\\/\\d{2})\\s+\\d{2}\\/\\d{2}\\s+(.*?)\\s+(-?\\$\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?|\\d+(?:\\.\\d{2})?)\\n\", text)\n",
    "            this_activites += re.findall(r\"(\\d{2}\\/\\d{2})\\s+\\d{2}\\/\\d{2}(\\s+.*?\\s+|\\s)(-?\\$\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?)\", text)\n",
    "    for i, activity in enumerate(this_activites):\n",
    "        txn_date = activity[0] + \"/\" + (str(int(year)-1) if activity[0][:2] == \"12\" and month == \"01\" else year)\n",
    "        this_activites[i] = (txn_date, activity[1].strip(), activity[2].replace(\"$\",\"\"))  # Update the tuple at index i\n",
    "    activities += this_activites\n",
    "\n",
    "old_spending_df = pd.DataFrame(activities, columns=['Transaction Date','Description','Amount'])\n",
    "old_spending_df[\"Transaction Date\"] = pd.to_datetime(old_spending_df[\"Transaction Date\"], format=\"%m/%d/%Y\")\n",
    "\n",
    "citibank_spending_df = pd.concat([old_spending_df,citibank_spending_df], ignore_index=True)\n",
    "\n",
    "# insert a column \n",
    "citibank_spending_df.insert(2, \"Category\", \"Shopping\")\n",
    "\n",
    "# assign Category base on Description\n",
    "citibank_spending_df[\"Category\"] = citibank_spending_df[\"Description\"].apply(assign_category)\n",
    "citibank_spending_df[\"Amount\"] = citibank_spending_df[\"Amount\"].astype(float)\n",
    "\n",
    "\n",
    "citibank_spending_df = citibank_spending_df.sort_values(by=\"Transaction Date\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac5b111",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_spending_df = pd.concat([spending_df,citibank_spending_df], ignore_index=True)\n",
    "total_spending_df = total_spending_df.sort_values(by=\"Transaction Date\", ascending=False)\n",
    "#total_spending_df.to_csv(f\"combined3.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5273e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# spending_df = citibank_spending_df\n",
    "\n",
    "monthly_category_spending = (\n",
    "    total_spending_df.groupby([total_spending_df['Transaction Date'].dt.to_period('Q'), 'Category'])['Amount']\n",
    "    .sum()\n",
    "    .unstack(fill_value=0)\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "monthly_category_spending.index = monthly_category_spending.index.to_timestamp()\n",
    "\n",
    "plt.figure(figsize=(14,7))\n",
    "monthly_category_spending.plot(kind='bar', stacked=True, figsize=(16,8))\n",
    "\n",
    "plt.title('Monthly Spending By Category', fontsize=16)\n",
    "plt.xlabel(\"Month\", fontsize=12)\n",
    "plt.ylabel(\"Spending ($)\", fontsize=12)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.legend(title=\"Category\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fdbaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_spending_df[\n",
    "    (total_spending_df[\"Transaction Date\"]>='2018/07/01') & \n",
    "    (total_spending_df[\"Transaction Date\"]< '2018/10/01') & \n",
    "    (total_spending_df[\"Category\"]==\"Shopping\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94d7399",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_spending_df[total_spending_df[\"Description\"].str.contains(\"JEUNESSE\", case=False)] # [\"Amount\"].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spending (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
